#K-fold Cross Validation
set.seed(1234)
for(i in 1:k){
best_fit <- regsubsets(Log_Apps ~ . - Apps, data = train[folds != i,], nvmax = 16, method = "exhaustive")
for(j in 1:18){
pred <- predict_regsubsets(best_fit, newdata = train[folds == i,], id = j)
cv_errors[i, j] <- mean((train$Log_Apps[folds == i] - pred) ^ 2)
}
}
set.seed(1234)
for(i in 1:k){
best_fit <- regsubsets(Log_Apps ~ . - Apps, data = train[folds != i,], nvmax = 16, method = "exhaustive")
for(j in 1:16){
pred <- predict_regsubsets(best_fit, newdata = train[folds == i,], id = j)
cv_errors[i, j] <- mean((train$Log_Apps[folds == i] - pred) ^ 2)
}
}
View(cv_errors)
mean_cv_errors <- apply(cv_errors, 2, mean)
mean_cv_errors
plot(mean_cv_errors, type = "b")
which.min(mean_cv_errors)
#Coefficients of the best model
coef(bestsub_1, 6) #Model w/ 6 variables
bestsub_cv_1 <- lm(Log_Apps ~ Accept + Enroll + PhD + S.F.Ratio + Expend + Grad.Rate, data = train)
summary(bestsub_cv_1)
#Test the Model----------------------------------
#Prediction
pred_bestsub_cv <- predict(bestsub_cv_1, test)
pred_bestsub_cv <- exp(pred_bestsub_cv)
summary(pred_bestsub_cv)
#Absolute error mean, median, sd, max, min-------
abs_err_bestsub_cv <- abs(pred_bestsub_cv - test$Apps)
mean(abs_err_bestsub_cv)
median(abs_err_bestsub_cv)
sd(abs_err_bestsub_cv)
range(abs_err_bestsub_cv)
#histogram and boxplot
hist(abs_err_bestsub_cv, breaks = 15)
boxplot(abs_err_bestsub_cv)
#Actual vs. Predicted
plot(test$Apps, pred_bestsub_cv, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
#Model 5: Best Sub Selection Using Trimmed Train and CV--------------
#Add Log Salary
trimmed_train$Log_Apps <- log(trimmed_train$Apps)
trimmed_bestsub_1 <- regsubsets(Log_Apps ~ . - Apps, nvmax = 16, data = trimmed_train, method = "exhaustive")
summary(trimmed_bestsub_1)
which.max(summary(trimmed_bestsub_1)$adjr2)
which.min(summary(trimmed_bestsub_1)$cp)
which.min(summary(trimmed_bestsub_1)$bic)
#Coefficients of the best model
coef(trimmed_bestsub_1, 6) #Model w/ 10 variables
#Coefficients of the best model
coef(trimmed_bestsub_1, 9) #Model w/ 10 variables
#Coefficients of the best model
coef(trimmed_bestsub_1, 11) #Model w/ 10 variables
trimmed_bestsub_2 <- lm(Log_Apps ~ Accept + Top10perc + terminal + S.F.Ratio + Expend + Grad.Rate, data = trimmed_train)
trimmed_bestsub_2 <- lm(Log_Apps ~ Accept + Top10perc + Terminal + S.F.Ratio + Expend + Grad.Rate, data = trimmed_train)
summary(trimmed_bestsub_2)
trimmed_bestsub_2 <- lm(Log_Apps ~ Accept + Top25perc + F.Undergrad + P.Undergrad + Books + PhD + S.F.Ratio + Expend + Grad.Rate, data = trimmed_train)
summary(trimmed_bestsub_2)
trimmed_bestsub_2 <- lm(Log_Apps ~ Accept + Top10perc + Top25perc + F.Undergrad + P.Undergrad + Books + PhD + terminal + S.F.Ratio + Expend + Grad.Rate, data = trimmed_train)
trimmed_bestsub_2 <- lm(Log_Apps ~ Accept + Top10perc + Top25perc + F.Undergrad + P.Undergrad + Books + PhD + Terminal + S.F.Ratio + Expend + Grad.Rate, data = trimmed_train)
summary(trimmed_bestsub_2)
which.max(summary(trimmed_bestsub_1)$adjr2)
which.min(summary(trimmed_bestsub_1)$cp)
which.min(summary(trimmed_bestsub_1)$bic)
#Coefficients of the best model
coef(trimmed_bestsub_1, 6) #Model w/ 10 variables
trimmed_bestsub_2 <- lm(Log_Apps ~ Accept + Top10perc + Terminal + S.F.Ratio + Expend + Grad.Rate, data = trimmed_train)
summary(trimmed_bestsub_2)
#Test the Model----------------------------------
#Prediction
pred_trimmed_bestsub  <- predict(trimmed_bestsub_2, test)
pred_trimmed_bestsub  <- exp(pred_trimmed_bestsub)
pred_trimmed_bestsub
#Absolute error mean, median, sd, max, min-------
abs_err_trimmed_bestsub <- abs(pred_trimmed_bestsub - test$Apps)
mean(abs_err_trimmed_bestsub)
median(abs_err_trimmed_bestsub)
sd(abs_err_trimmed_bestsub)
range(abs_err_trimmed_bestsub)
#histogram and boxplot
hist(abs_err_trimmed_bestsub, breaks = 15)
boxplot(abs_err_trimmed_bestsub)
#Actual vs. Predicted
plot(test$Apps, pred_trimmed_bestsub, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
df <- data.frame("Model_1" = abs_err_lm,
"Model_3" = abs_err_bestsub,
"Model_4" = abs_err_bestsub_cv,
"Model_5" = abs_err_trimmed_bestsub)
models_comp <- data.frame("Mean of AbsErrors"   = apply(df, 2, mean),
"Median of AbsErrors" = apply(df, 2, median),
"SD of AbsErrors"  = apply(df, 2, sd),
"IQR of AbsErrors" = apply(df, 2, IQR),
"Min of AbsErrors" = apply(df, 2, min),
"Max of AbsErrors" = apply(df, 2, max))
rownames(models_comp) <- c("LM", "BestSub", "BestSubCV", "TrimmedBestSub")
View(models_comp)
plot(models_comp)
#Boxplot of absolute errors
boxplot(df, main = "Abs. Errors Dist. of Models")
#Save the results--------------------------------
save(data2, train, trimmed_train, test, models_comp, file = "college_dataset_v1.R")
#Boxplot of absolute errors
boxplot(df, main = "Abs. Errors Dist. of Models")
#Boxplot of absolute errors
boxplot(df, main = "Abs. Errors Dist. of Models")
View(models_comp)
x <- model.matrix(Log_Apps ~ + . - Apps, data = train)[, -1] #remove intercept
y <- train$Log_Apps
lambda_ridge_grid <- 10 ^ seq(10, -2, length = 100)
lambda_ridge_grid
summary(x)
head(x)
head(y)
#Apply Ridge Regression
ridgereg_1 <- glmnet(x, y, alpha = 0, lambda = lambda_ridge_grid)
library("glmnet")         #Lasso and Elastic-Net Regularized GLM
library("rpart")          #Classification and Regression Trees
library("rpart.plot")     #Plot Decision Tree
library("randomForest")   #Random Forests for Classification and Regression
#Apply Ridge Regression
ridgereg_1 <- glmnet(x, y, alpha = 0, lambda = lambda_ridge_grid)
dim(coef(ridgereg_1))
head(coef(ridgereg_1))
summary((coef(ridgereg_1)))
dim(coef(ridgereg_1))
ridgereg_1
#Plot Reg. Coefficients vs. Log Lambda
plot(ridgereg_1, xvar = "lambda")
#Retrieve Coefficients
ridgereg_1$lambda [50]
coef(ridgereg_1)[, 50]
#Cross validation to choose the best model
set.seed(1234)
ridge_cv    <- cv.glmnet(x, y, alpha = 0, nfolds = 10)
#The mean cross-validated error
ridge_cv$cvm
#Estimate of standard error of cvm.
ridge_cv$cvsd
#value of lambda that gives minimum cvm
ridge_cv$lambda.min
#Coefficients of regression w/ best_lambda
ridgereg_2 <- glmnet(x, y, alpha = 0, lambda = ridge_cv$lambda.min)
coef(ridgereg_2)
#Test the Model----------------------------------
#Prediction
#Create model matrix for test
test$Log_Apps <- log(test$Apps)
x_test <- model.matrix(Log_Apps ~ + . - Apps, data = test)[, -1]#remove intercept
pred_ridgereg <- predict(ridgereg_2, s = ridge_cv$lambda.min, newx = x_test)
pred_ridgereg
pred_ridgereg <- exp(pred_ridgereg)
pred_ridgereg
#Absolute error mean, median, sd, max, min-------
abs_err_ridgereg <- abs(pred_ridgereg - test$Apps)
models_comp <- rbind(models_comp, "RidgeReg" = c(mean(abs_err_ridgereg),
median(abs_err_ridgereg),
sd(abs_err_ridgereg),
IQR(abs_err_ridgereg),
range(abs_err_ridgereg)))
View(models_comp)
#Actual vs. Predicted
plot(test$Apps, pred_ridgereg, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
#Apply Lasso Regression
lassoreg_1 <- glmnet(x, y, alpha = 1, lambda = lambda_ridge_grid)
dim(coef(lassoreg_1))
#Plot Reg. Coefficients vs. Log Lambda
plot(lassoreg_1, xvar = "lambda")
#Retrieve Coefficients
lassoreg_1$lambda [90]
coef(lassoreg_1)[, 90]
#Cross validation to choose the best model
set.seed(1234)
lasso_cv    <- cv.glmnet(x, y, alpha = 1, nfolds = 10)
#The mean cross-validated error
lasso_cv$cvm
#Estimate of standard error of cvm.
lasso_cv$cvsd
#value of lambda that gives minimum cvm
lasso_cv$lambda.min
#Coefficients of regression w/ best_lambda
lassoreg_2 <- glmnet(x, y, alpha = 1, lambda = lasso_cv$lambda.min)
coef(lassoreg_2)
#Test the Model----------------------------------
#Prediction
pred_lassoreg <- predict(lassoreg_2, s = lasso_cv$lambda.min, newx = x_test)
View(pred_lassoreg)
pred_lassoreg
pred_lassoreg <- exp(pred_lassoreg)
pred_lassoreg
#Absolute error mean, median, sd, max, min-------
abs_err_lassoreg <- abs(pred_lassoreg - test$Apps)
models_comp <- rbind(models_comp, "LassoReg" = c(mean(abs_err_lassoreg),
median(abs_err_lassoreg),
sd(abs_err_lassoreg),
IQR(abs_err_lassoreg),
range(abs_err_lassoreg)))
View(models_comp)
#Actual vs. Predicted
plot(test$Apps, pred_lassoreg, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
#Model 7: Decision Trees-------------------------
tree_1 <- rpart(Log_Apps ~ Accept + Top10perc + Grad.Rate , data = train, cp = 0.1, maxdepth = 3)
#Plot the tree
prp(tree_1)
#Decision Tree Structure
tree_1
#Change Complexity of Tree Model
tree_2 <- rpart(Log_Apps ~ Accept + Top10perc + Grad.Rate , data = train, cp = 0.001, maxdepth = 10)
#Plot the tree
prp(tree_2)
plotcp(tree_2)
tree_2$cptable
tree_2$cptable[which.min(tree_2$cptable[,"xerror"])]
#Prune the tree
tree_3 <- prune.rpart(tree_2, cp = tree_2$cptable[which.min(tree_2$cptable[,"xerror"])])
#Plot the pruned tree
prp(tree_3)
#Decision Tree Model Using All Variables
tree_4 <- rpart(formula = Log_Apps ~ . - Apps, data = train, cp = 0.0001, maxdepth = 20)
#Plot the tree
prp(tree_4)
#Prune the tree
plotcp(tree_4)
tree_4$cptable[which.min(tree_4$cptable[,"xerror"])]
#Prune the tree
tree_5 <- prune.rpart(tree_4, cp = tree_4$cptable[which.min(tree_4$cptable[,"xerror"])])
#Plot the tree
prp(tree_5)
#Test the Model----------------------------------
#Prediction:
pred_tree  <- predict(tree_5, test)
pred_tree  <- exp(pred_tree)
pred_tree
#Absolute error mean, median, sd, max, min-------
abs_err_tree <- abs(pred_tree - test$Apps)
models_comp <- rbind(models_comp, "Tree" = c(mean(abs_err_tree),
median(abs_err_tree),
sd(abs_err_tree),
IQR(abs_err_tree),
range(abs_err_tree)))
View(models_comp)
#Actual vs. Predicted
plot(test$Apps, pred_tree, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
#Model 8: Bagging--------------------------------
set.seed(1234)
bagging_1 <- randomForest(Log_Apps ~ . - Apps, mtry = ncol(train) - 2, ntree = 500, data = train)
bagging_1
#Test the Model----------------------------------
#Prediction: M8 Bagging
pred_bagging  <- predict(bagging_1, test)
pred_bagging  <- exp(pred_bagging)
pred_bagging
#Absolute error mean, median, sd, max, min-------
abs_err_bagging <- abs(pred_bagging - test$Apps)
models_comp <- rbind(models_comp, "Bagging" = c(mean(abs_err_bagging),
median(abs_err_bagging),
sd(abs_err_bagging),
IQR(abs_err_bagging),
range(abs_err_bagging)))
View(models_comp)
#Actual vs. Predicted
plot(test$Apps, pred_bagging, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
library(readr)            #import .CSV files
library("corrplot")       #Visualization of Correlation Matrix
library("moments")        #Moments, skewness, kurtosis and related tests
library("MASS")           #Box-Cox Transformations for Linear Models
library("leaps")          #Regression Subset Selection
library("glmnet")         #Lasso and Elastic-Net Regularized GLM
library("rpart")          #Classification and Regression Trees
library("rpart.plot")     #Plot Decision Tree
library("randomForest")   #Random Forests for Classification and Regre
#Model 9: Random Forrest-------------------------
set.seed(1234)
rf_1 <- randomForest(Log_Apps ~ . - Apps, data = train, ntree = 500, importance = TRUE)
#mtry
#     for regression = p/3
rf_1
importance(rf_1)
varImpPlot(rf_1)
#K-fold Cross-Validation for feature selection
#Don't forget to remove "Salary"[16] & "Log_Salary"[18]
#step = 0.75,
#step 1: 16, step 2: example: round(0.75 * 16) = 12
#mtry: a function of number of remaining predictor variables to use
#as the mtry parameter in the randomForest call
#example: default: floor(sqrt(p)), floor(p/3)
#recursive: whether variable importance is (re-)assessed at each step of variable reduction
set.seed(12345)
dim(log)
dim(Log_Apps)
dim(train$Log_Apps)
train$Log_Apps
nrow(train$Log_Apps)
ncol(train$Log_Apps)
nrow(train$Log_Apps)
row(train$Log_Apps)
View(train$Log_Apps)
summary(train$Log_Apps)
str(train$Log_Apps)
class(train$Log_Apps)
typeof(train$Log_Apps)
set.seed()
seed
seed()
View(train)
rf_cv <- rfcv(train[, - c(1, 18)],
train$Log_Apps,
cv.fold = 10,
step = 0.75,
mtry = function(p) max(1, floor(sqrt(p))),
recursive = FALSE)
class(rf_cv)
str(rf_cv)
#Vector of number of variables used at each step
rf_cv$n.var
#Corresponding vector of MSEs at each step
rf_cv$error.cv
which.min(rf_cv$error.cv)
#Remove 8 variables based on Importance of Variables
sort(importance(rf_1)[,1])
#Regression formula
reg_formula <- as.formula(Log_Apps ~ Accept + Enroll + F.Undergrad + Outstate + Top10perc + Expend + Room.Board + Grad.Rate + Top25perc)
reg_formula
#mtry
floor(sqrt(10))
#mtry
floor(sqrt(9))
set.seed(1234)
rf_2 <- randomForest(reg_formula, data = train, mtry = 3, ntree = 500)
rf_2
#Model 10: Bagging w/ Trimmed Train--------------
set.seed(1234)
trimmedbagging_1 <- randomForest(Log_Apps ~ . - Apps, mtry = ncol(trimmed_train) - 2, ntree = 500, data = trimmed_train)
trimmedbagging_1
#Test the Model----------------------------------
#Prediction:
pred_trimmedbagging  <- predict(trimmedbagging_1, test)
pred_trimmedbagging  <- exp(pred_trimmedbagging)
pred_trimmedbagging
#Absolute error mean, median, sd, max, min-------
abs_err_trimmedbagging <- abs(pred_trimmedbagging - test$Apps)
models_comp <- rbind(models_comp, "TrimmedBagging" = c(mean(abs_err_trimmedbagging),
median(abs_err_trimmedbagging),
sd(abs_err_trimmedbagging),
IQR(abs_err_trimmedbagging),
range(abs_err_trimmedbagging)))
View(models_comp)
#Actual vs. Predicted
plot(test$Apps, pred_trimmedbagging, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
#Save the results--------------------------------
save(data2, train, trimmed_train, test, models_comp, file = "case4_dataset_v2.R")
college <- read.csv("College.csv", header = TRUE)
data1 <- college
View(data1)
data1[, cat_var] <- lapply(data1[, cat_var], factor)
#Convert categorical variables to factor
cat_var <- "Private"
data1[, cat_var] <- lapply(data1[, cat_var], factor)
college <- read.csv("College.csv", header = TRUE)
data1 <- college
library("corrplot")       #Visualization of Correlation Matrix
library("moments")        #Moments, skewness, kurtosis and related tests
library("MASS")           #Box-Cox Transformations for Linear Models
library("leaps")          #Regression Subset Selection
library("glmnet")         #Lasso and Elastic-Net Regularized GLM
library("rpart")          #Classification and Regression Trees
library("rpart.plot")     #Plot Decision Tree
library("randomForest")   #Random Forests for Classification and Regression
cat_var <- "Private"
data1[, cat_var] <- lapply(data1[, cat_var], factor)
data1[, "Private"] <- lapply(data1[, "Private"], factor)
#Scatter Plot
par(mar = c(2, 2, 2, 2))
par(mfrow = c(3, 6))  # 3 rows and 6 columns
for (i in c(1:17)) {
plot(data2[,i], data2$Apps, xlab = "", main = paste("Apps vs.", names(data2)[i]))
}
ibrary(readr)            #import .CSV files
library("corrplot")       #Visualization of Correlation Matrix
library("moments")        #Moments, skewness, kurtosis and related tests
library("MASS")           #Box-Cox Transformations for Linear Models
library("leaps")          #Regression Subset Selection
library("glmnet")         #Lasso and Elastic-Net Regularized GLM
library("rpart")          #Classification and Regression Trees
library("rpart.plot")     #Plot Decision Tree
library("randomForest")   #Random Forests for Classification and Regression
##Required libraries-----------------------------
library(readr)            #import .CSV files
hist(lm_2$residuals, probability = TRUE, breaks = 25)
lines(density(lm_2$residuals), col = "red")
hist(lm_2$residuals, probability = TRUE, breaks = 25)
lines(density(lm_2$residuals), col = "red")
hist(lm_2$residuals, probability = TRUE, breaks = 25)
lines(density(lm_2$residuals), col = "red")
qqnorm(lm_2$residuals, main = "QQ Plot of residuals", pch = 20)
qqline(lm_2$residuals, col = "red")
hist(lm_2$residuals, probability = TRUE, breaks = 25)
lines(density(lm_2$residuals), col = "red")
college <- read.csv("College.csv", header = TRUE)
data1 <- college
#Convert categorical variables to factor
cat_var <- c("Private")
data1[, cat_var] <- lapply(data1[, cat_var], factor)
#Dealing w/ MVs
#Analysis of MVs should be done:
sum(is.na(data1))
#Remove "university Names" and "Private" column:
data2 <- data1[,-c(1,2)]
sum(is.na(data2))
#Continuous variables distribution
par(mar = c(2, 2, 2, 2))
par(mfrow = c(3, 6))  # 3 rows and 6 columns
for (i in c(1:17)) {
hist(data2[,i], xlab = "", main = paste("Hist. of", names(data2)[i]))
}
par(mfrow = c(1, 1))
boxplot(data2$Apps, main = "Apps Dist.")
#Identify outliers
tukey_ul <- quantile(data2$Apps, probs = 0.75) + 1.5 * IQR(data2$Apps)
tukey_ul
sum(data2$Apps > tukey_ul)
#Correlation Analysis
cor_table <- round(cor(data2[, c(1:17)]), 2)
#Scatter Plot
par(mar = c(2, 2, 2, 2))
par(mfrow = c(3, 6))  # 3 rows and 6 columns
for (i in c(1:17)) {
plot(data2[,i], data2$Apps, xlab = "", main = paste("Apps vs.", names(data2)[i]))
}
#Divide Dataset into Train and Test--------------
set.seed(1234)
train_cases <- sample(1:nrow(data2), nrow(data2) * 0.8)
train <- data2[train_cases,]
test  <- data2[- train_cases,]
#Train dataset w/o outliers
trimmed_train <- train[- which(train$Apps > tukey_ul), ]
dim(trimmed_train)
summary(trimmed_train$Apps)
##Building Prediction Model----------------------
#Model1 : Traditional Linear Regression----------
lm_1 <- lm(Apps ~ ., data = train)
summary(lm_1)
lm_2 <- lm(Apps ~ Enroll + Top10perc + Top25perc + Outstate + Expend + Grad.Rate , data = train)
summary(lm_2)
#Check Assumptions of Regression
#Normality of residuals
hist(lm_2$residuals, probability = TRUE, breaks = 25)
lines(density(lm_2$residuals), col = "red")
hist(lm_2$residuals, probability = TRUE, breaks = 25)
lines(density(lm_2$residuals), col = "red")
qqnorm(lm_2$residuals, main = "QQ Plot of residuals", pch = 20)
qqline(lm_2$residuals, col = "red")
plot(lm_2)
#Check multicollinearity
car :: vif(lm_1)
#Model2 : Box-Cox Transformation-----------------
#Box-Cox Transformation
box_results <- boxcox(Apps ~ ., data = train, lambda = seq(-5, 5, 0.1))
box_results <- data.frame(box_results$x, box_results$y)            # Create a data frame with the results
lambda <- box_results[which(box_results$box_results.y == max(box_results$box_results.y)), 1]
lambda
library(readr)            #import .CSV files
library("corrplot")       #Visualization of Correlation Matrix
library("moments")        #Moments, skewness, kurtosis and related tests
library("MASS")           #Box-Cox Transformations for Linear Models
library("leaps")          #Regression Subset Selection
library("glmnet")         #Lasso and Elastic-Net Regularized GLM
library("rpart")          #Classification and Regression Trees
library("rpart.plot")     #Plot Decision Tree
library("randomForest")   #Random Forests for Classification and Regression
plot(summary(bestsub_1)$adjr2, type="b", xlab="# of Variables", ylab="AdjR2", xaxt='n', xlim=c(1, 16)); grid()
axis(1, at=1:16, labels=1:16)
points(which.max(summary(bestsub_1)$adjr2), summary(bestsub_1)$adjr2[which.max(summary(bestsub_1)$adjr2)], col = "red", cex = 2, pch = 20)
#Coefficients of the best model
coef(bestsub_1, 14) #Model w/ 9 variables
bestsub_2 <- lm(Log_Apps ~ Accept + Enroll + Top25perc + Room.Board + PhD + S.F.Ratio + perc.alumni + Expend + Grad.Rate, data = train)
summary(bestsub_2)
#Coefficients of the best model
coef(bestsub_1, 11) #Model w/ 9 variables
bestsub_2 <- lm(Log_Apps ~ Accept + Enroll + Top25perc + P.Undergrad + Room.Board + Books + PhD + S.F.Ratio + perc.alumni + Expend + Grad.Rate, data = train)
summary(bestsub_2)
#Coefficients of the best model
coef(bestsub_1, 14) #Model w/ 9 variables
bestsub_2 <- lm(Log_Apps ~ Accept + Enroll + Top25perc + P.Undergrad + Outstate + Room.Board + Books + Personal + PhD + Terminal + S.F.Ratio + perc.alumni + Expend + Grad.Rate, data = train)
summary(bestsub_2)
#Plot BIC
plot(summary(bestsub_1)$bic, type = "b", xlab = "# of Variables", ylab = "BIC", xaxt = 'n', xlim = c(1, 16)); grid()
axis(1, at = 1:16, labels = 1:16)
points(which.min(summary(bestsub_1)$bic), summary(bestsub_1)$bic[which.min(summary(bestsub_1)$bic)], col = "red", cex = 2, pch = 20)
#Coefficients of the best model
coef(bestsub_1, 9) #Model w/ 9 variables
bestsub_2 <- lm(Log_Apps ~ Accept + Enroll + Top25perc + Room.Board + PhD + S.F.Ratio + perc.alumni + Expend + Grad.Rate, data = train)
summary(bestsub_2)
##Required libraries-----------------------------
library(readr)            #import .CSV files
library("corrplot")       #Visualization of Correlation Matrix
library("moments")        #Moments, skewness, kurtosis and related tests
library("MASS")           #Box-Cox Transformations for Linear Models
library("leaps")          #Regression Subset Selection
library("glmnet")         #Lasso and Elastic-Net Regularized GLM
library("rpart")          #Classification and Regression Trees
library("rpart.plot")     #Plot Decision Tree
library("randomForest")   #Random Forests for Classification and Regression
